{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOiZdm3p+cV7/47eV2COa4E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ktynski/Marketing_Automations_Notebooks_With_GPT/blob/main/Automatic_Schema_Improvements_with_GPT4_(Public).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDdmB7FGGJHV"
      },
      "outputs": [],
      "source": [
        "!pip install bs4\n",
        "!pip install openai\n",
        "!pip install transformers\n",
        "!pip install newspaper3k"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import json\n",
        "import requests\n",
        "from transformers import GPT2Tokenizer\n",
        "from newspaper import Article\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Define your OpenAI GPT-3 API key\n",
        "openai.api_key = \"Your OpenAI Api Key\"\n",
        "\n",
        "\n",
        "\n",
        "def truncate_string_to_tokens(content, max_tokens):\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "    content_tokens = tokenizer.tokenize(content)\n",
        "    print(len(content_tokens))\n",
        "    if len(content_tokens) > max_tokens:\n",
        "        content_tokens = content_tokens[:max_tokens]\n",
        "    truncated_content = tokenizer.convert_tokens_to_string(content_tokens)\n",
        "    return truncated_content\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Function to call GPT-3 and get a response\n",
        "def gpt4_response(prompt):\n",
        "    response = openai.ChatCompletion.create(\n",
        "                model=\"gpt-4\",\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": \"Please simulate an expert at SEO Schema. Your goal is to think step by step and provide the highest quality, most accurate result possible for the given question.\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": f\"{prompt}\"\n",
        "                    }\n",
        "                ],\n",
        "                max_tokens=1000,\n",
        "                n=1,\n",
        "                stop=None,\n",
        "                temperature=0.7,\n",
        "\n",
        "            )\n",
        "\n",
        "    result = response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
        "    return result\n",
        "\n",
        "# Function to enhance HTML with schema markup using GPT-3\n",
        "def enhance_html_with_schema(url):\n",
        "    # Use newspaper3k to extract relevant information from the URL\n",
        "    article = Article(url)\n",
        "    article.download()\n",
        "    article.parse()\n",
        "\n",
        "    # Prepare content for GPT-3 analysis\n",
        "    content = f\"Title: {article.title}\\n\"\n",
        "    content += f\"Author: {article.authors}\\n\"\n",
        "    content += f\"Publication Date: {article.publish_date}\\n\"\n",
        "    content += f\"Content: {article.text}\\n\"\n",
        "\n",
        "    # Truncate content to fit within GPT-3's token limit. If you do not have GPT4, you will need to change the 3500 to 1500 and it may not fit the full html.\n",
        "    content = truncate_string_to_tokens(content, 3500)\n",
        "\n",
        "    # Analyze content and determine schema type\n",
        "    schema_type_prompt = f\"What schema type should be applied to the following content from URL {url}?\\n{content}\\nSchema type:\"\n",
        "    schema_type = gpt4_response(schema_type_prompt)\n",
        "\n",
        "    # Extract relevant data points (with example)\n",
        "    data_points_prompt = (\n",
        "\n",
        "        f\"Data points (Simple example for format, yours will be much more comprehensive.Example format: {{\\\"title\\\": \\\"Sample Title\\\", \\\"author\\\": \\\"John Doe\\\", \\\"datePublished\\\": \\\"2023-05-01\\\"}}):\"\n",
        "        f\"Extract relevant data points for {schema_type} schema from the following content from URL {url}:\\n\"\n",
        "        f\"{content}\\n\"\n",
        "        f\"Use all possible Schema improvements. Remember there are hundreds of potential ways schema might be applied. Your job is to find all possible ways to leverage schema to improve the given html. \\n Please go well beyond the example wherever possible. After providing the updated html, also provide a readout/report of the update that would be useful to a client or SEO. Include as many improvements as possible. \\n Updated HTML with Schema Applied and final readout/summary:\"\n",
        "\n",
        "    )\n",
        "    data_points_text = gpt4_response(data_points_prompt)\n",
        "    return str(data_points_text)\n",
        "\n",
        "\n",
        "\n",
        "# Sample URL input\n",
        "url_input = 'https://www.frac.tl/conservative-brands-content-creation/'\n",
        "\n",
        "# Enhance HTML with schema markup using GPT-3\n",
        "enhanced_html = enhance_html_with_schema(url_input)\n",
        "\n",
        "# Save the enhanced HTML to a text file\n",
        "with open('enhanced_html_output.txt', 'w', encoding='utf-8') as file:\n",
        "    file.write(str(enhanced_html))\n",
        "\n",
        "print(\"Enhanced HTML from GPT4. This output has also been saved to 'enhanced_html_output.txt'\")\n",
        "print(enhanced_html)\n"
      ],
      "metadata": {
        "id": "rL-UYrcMGNY_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}